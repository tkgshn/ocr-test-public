"""
OCRçµæœã®å¯è¦–åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
åº§æ¨™ãƒ‡ãƒ¼ã‚¿ä»˜ããƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºæ©Ÿèƒ½
"""
import streamlit as st
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import io
import base64
from typing import Dict, List, Any, Optional, Tuple
import json
import time


class OCRVisualizer:
    """
    OCRçµæœã®å¯è¦–åŒ–ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹
    """

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.colors = [
            "#FF6B6B",  # èµ¤
            "#4ECDC4",  # ãƒ†ã‚£ãƒ¼ãƒ«
            "#45B7D1",  # é’
            "#96CEB4",  # ç·‘
            "#FFEAA7",  # é»„
            "#DDA0DD",  # ãƒ—ãƒ©ãƒ 
            "#98D8C8",  # ãƒŸãƒ³ãƒˆ
            "#F7DC6F",  # ã‚´ãƒ¼ãƒ«ãƒ‰
            "#BB8FCE",  # ãƒ©ãƒ™ãƒ³ãƒ€ãƒ¼
            "#85C1E9"   # ã‚¹ã‚«ã‚¤ãƒ–ãƒ«ãƒ¼
        ]

    def create_highlighted_image(self,
                                image_file,
                                ocr_result: Dict[str, Any],
                                highlight_level: str = "paragraphs") -> Optional[Image.Image]:
        """
        OCRçµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã—ãŸç”»åƒã‚’ä½œæˆ

        Args:
            image_file: å…ƒã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
            ocr_result: OCRå‡¦ç†çµæœ
            highlight_level: ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ« ("blocks", "paragraphs", "lines", "tokens")

        Returns:
            PIL.Image: ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚ŒãŸç”»åƒ
        """
        try:
            # ç”»åƒã‚’èª­ã¿è¾¼ã¿
            if hasattr(image_file, 'read'):
                image_file.seek(0)
                image = Image.open(image_file)
            else:
                image = Image.open(image_file)

            # RGBAãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›ï¼ˆé€æ˜åº¦ã‚’æ‰±ã†ãŸã‚ï¼‰
            if image.mode != 'RGBA':
                image = image.convert('RGBA')

            # æç”»ç”¨ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ä½œæˆ
            overlay = Image.new('RGBA', image.size, (255, 255, 255, 0))
            draw = ImageDraw.Draw(overlay)

            # OCRçµæœã‹ã‚‰ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±ã‚’æŠ½å‡º
            if ocr_result.get("success") and ocr_result.get("data"):
                data = ocr_result["data"]

                if ocr_result.get("source") == "document_ai":
                    self._draw_document_ai_highlights(draw, data, highlight_level, image.size)
                # OpenAIã®å ´åˆã¯ä½•ã‚‚æç”»ã—ãªã„ï¼ˆstreamlitå´ã§ãƒ†ã‚­ã‚¹ãƒˆã®ã¿è¡¨ç¤ºï¼‰

            # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’å…ƒç”»åƒã«åˆæˆ
            highlighted_image = Image.alpha_composite(image, overlay)

            # RGBãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›ï¼ˆè¡¨ç¤ºç”¨ï¼‰
            return highlighted_image.convert('RGB')

        except Exception as e:
            st.error(f"ãƒã‚¤ãƒ©ã‚¤ãƒˆç”»åƒã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None

    def _draw_document_ai_highlights(self,
                                   draw: ImageDraw.Draw,
                                   data: Dict[str, Any],
                                   highlight_level: str,
                                   image_size: Tuple[int, int]):
        """
        Document AI ã®çµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º

        Args:
            draw: ImageDraw ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            data: Document AI ã®çµæœãƒ‡ãƒ¼ã‚¿
            highlight_level: ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«
            image_size: ç”»åƒã‚µã‚¤ã‚º (width, height)
        """
        if "pages" not in data or not data["pages"]:
            return

        page = data["pages"][0]  # æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†

        # ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦æç”»
        if highlight_level in page:
            elements = page[highlight_level]

            for i, element in enumerate(elements):
                if element.get("bounding_box"):
                    color_idx = i % len(self.colors)
                    color = self.colors[color_idx]

                    # åº§æ¨™ã‚’å–å¾—
                    bbox = element["bounding_box"]

                    # æ­£è¦åŒ–åº§æ¨™ã‚’ä½¿ç”¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                    if bbox.get("normalized_vertices"):
                        vertices = self._convert_normalized_vertices(
                            bbox["normalized_vertices"], image_size
                        )
                    elif bbox.get("vertices"):
                        vertices = [(v["x"], v["y"]) for v in bbox["vertices"]]
                    else:
                        continue

                    # ãƒãƒªã‚´ãƒ³ã‚’æç”»
                    self._draw_polygon_highlight(draw, vertices, color, element.get("text", ""))

    def _convert_normalized_vertices(self,
                                   normalized_vertices: List[Dict[str, float]],
                                   image_size: Tuple[int, int]) -> List[Tuple[int, int]]:
        """
        æ­£è¦åŒ–åº§æ¨™ã‚’å®Ÿéš›ã®ç”»åƒåº§æ¨™ã«å¤‰æ›

        Args:
            normalized_vertices: æ­£è¦åŒ–åº§æ¨™ã®ãƒªã‚¹ãƒˆ
            image_size: ç”»åƒã‚µã‚¤ã‚º (width, height)

        Returns:
            å®Ÿéš›ã®åº§æ¨™ã®ãƒªã‚¹ãƒˆ
        """
        width, height = image_size
        vertices = []

        for vertex in normalized_vertices:
            x = int(vertex.get("x", 0) * width)
            y = int(vertex.get("y", 0) * height)
            vertices.append((x, y))

        return vertices

    def _draw_polygon_highlight(self,
                              draw: ImageDraw.Draw,
                              vertices: List[Tuple[int, int]],
                              color: str,
                              text: str = ""):
        """
        ãƒãƒªã‚´ãƒ³ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’æç”»

        Args:
            draw: ImageDraw ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            vertices: é ‚ç‚¹åº§æ¨™ã®ãƒªã‚¹ãƒˆ
            color: ãƒã‚¤ãƒ©ã‚¤ãƒˆè‰²
            text: è¡¨ç¤ºã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if len(vertices) < 3:
            return

        # åŠé€æ˜ã®å¡—ã‚Šã¤ã¶ã—
        fill_color = self._hex_to_rgba(color, alpha=50)
        draw.polygon(vertices, fill=fill_color)

        # å¢ƒç•Œç·š
        outline_color = self._hex_to_rgba(color, alpha=200)
        draw.polygon(vertices, outline=outline_color, width=2)

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ©ãƒ™ãƒ«ã¯è±†è…ãƒ•ã‚©ãƒ³ãƒˆå•é¡Œã‚’é¿ã‘ã‚‹ãŸã‚ã«å‰Šé™¤
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒæ­£ã—ãèª­ã¿è¾¼ã‚ãªã„ç¯å¢ƒã§ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«

    def _hex_to_rgba(self, hex_color: str, alpha: int = 255) -> Tuple[int, int, int, int]:
        """
        16é€²æ•°ã‚«ãƒ©ãƒ¼ã‚’RGBAã«å¤‰æ›

        Args:
            hex_color: 16é€²æ•°ã‚«ãƒ©ãƒ¼æ–‡å­—åˆ— (ä¾‹: "#FF6B6B")
            alpha: é€æ˜åº¦ (0-255)

        Returns:
            RGBA ã‚¿ãƒ—ãƒ«
        """
        hex_color = hex_color.lstrip('#')

        if len(hex_color) == 6:
            r = int(hex_color[0:2], 16)
            g = int(hex_color[2:4], 16)
            b = int(hex_color[4:6], 16)
            return (r, g, b, alpha)
        else:
            return (255, 0, 0, alpha)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯èµ¤

    def display_ocr_results_with_highlights(self,
                                          image_file,
                                          ocr_result: Dict[str, Any]):
        """
        OCRçµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãã§è¡¨ç¤º

        Args:
            image_file: å…ƒã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
            ocr_result: OCRå‡¦ç†çµæœ
        """
        # st.subheader("ğŸ“ OCRçµæœã®ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š
        if ocr_result.get("source") == "document_ai":
            highlight_level = "paragraphs"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§paragraphsã‚’ä½¿ç”¨
        else:
            highlight_level = "openai"
            st.info("OpenAI ã®çµæœã«ã¯åº§æ¨™æƒ…å ±ãŒãªã„ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

        # ãƒã‚¤ãƒ©ã‚¤ãƒˆç”»åƒã‚’ä½œæˆ
        highlighted_image = self.create_highlighted_image(
            image_file, ocr_result, highlight_level
        )

        if highlighted_image:
            # ç”»åƒã‚’è¡¨ç¤º
            st.image(highlighted_image)

        #     # # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
        #     # self._display_detailed_results(ocr_result, highlight_level)
        # else:
        #     st.error("ãƒã‚¤ãƒ©ã‚¤ãƒˆç”»åƒã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
