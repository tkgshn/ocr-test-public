"""
OCRçµæœã®å¯è¦–åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
åº§æ¨™ãƒ‡ãƒ¼ã‚¿ä»˜ããƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºæ©Ÿèƒ½
"""
import streamlit as st
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import io
import base64
from typing import Dict, List, Any, Optional, Tuple
import json
import time


class OCRVisualizer:
    """
    OCRçµæœã®å¯è¦–åŒ–ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹
    """

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.colors = [
            "#FF6B6B",  # èµ¤
            "#4ECDC4",  # ãƒ†ã‚£ãƒ¼ãƒ«
            "#45B7D1",  # é’
            "#96CEB4",  # ç·‘
            "#FFEAA7",  # é»„
            "#DDA0DD",  # ãƒ—ãƒ©ãƒ 
            "#98D8C8",  # ãƒŸãƒ³ãƒˆ
            "#F7DC6F",  # ã‚´ãƒ¼ãƒ«ãƒ‰
            "#BB8FCE",  # ãƒ©ãƒ™ãƒ³ãƒ€ãƒ¼
            "#85C1E9"   # ã‚¹ã‚«ã‚¤ãƒ–ãƒ«ãƒ¼
        ]

    def create_highlighted_image(self,
                                image_file,
                                ocr_result: Dict[str, Any],
                                highlight_level: str = "paragraphs") -> Optional[Image.Image]:
        """
        OCRçµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã—ãŸç”»åƒã‚’ä½œæˆ

        Args:
            image_file: å…ƒã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
            ocr_result: OCRå‡¦ç†çµæœ
            highlight_level: ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ« ("blocks", "paragraphs", "lines", "tokens")

        Returns:
            PIL.Image: ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚ŒãŸç”»åƒ
        """
        try:
            # ç”»åƒã‚’èª­ã¿è¾¼ã¿
            if hasattr(image_file, 'read'):
                image_file.seek(0)
                image = Image.open(image_file)
            else:
                image = Image.open(image_file)

            # RGBAãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›ï¼ˆé€æ˜åº¦ã‚’æ‰±ã†ãŸã‚ï¼‰
            if image.mode != 'RGBA':
                image = image.convert('RGBA')

            # æç”»ç”¨ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ä½œæˆ
            overlay = Image.new('RGBA', image.size, (255, 255, 255, 0))
            draw = ImageDraw.Draw(overlay)

            # OCRçµæœã‹ã‚‰ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±ã‚’æŠ½å‡º
            if ocr_result.get("success") and ocr_result.get("data"):
                data = ocr_result["data"]

                if ocr_result.get("source") == "document_ai":
                    self._draw_document_ai_highlights(draw, data, highlight_level, image.size)
                elif ocr_result.get("source") == "openai":
                    self._draw_openai_highlights(draw, data, image.size)

            # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’å…ƒç”»åƒã«åˆæˆ
            highlighted_image = Image.alpha_composite(image, overlay)

            # RGBãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›ï¼ˆè¡¨ç¤ºç”¨ï¼‰
            return highlighted_image.convert('RGB')

        except Exception as e:
            st.error(f"ãƒã‚¤ãƒ©ã‚¤ãƒˆç”»åƒã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None

    def _draw_document_ai_highlights(self,
                                   draw: ImageDraw.Draw,
                                   data: Dict[str, Any],
                                   highlight_level: str,
                                   image_size: Tuple[int, int]):
        """
        Document AI ã®çµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º

        Args:
            draw: ImageDraw ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            data: Document AI ã®çµæœãƒ‡ãƒ¼ã‚¿
            highlight_level: ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«
            image_size: ç”»åƒã‚µã‚¤ã‚º (width, height)
        """
        if "pages" not in data or not data["pages"]:
            return

        page = data["pages"][0]  # æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†

        # ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦æç”»
        if highlight_level in page:
            elements = page[highlight_level]

            for i, element in enumerate(elements):
                if element.get("bounding_box"):
                    color_idx = i % len(self.colors)
                    color = self.colors[color_idx]

                    # åº§æ¨™ã‚’å–å¾—
                    bbox = element["bounding_box"]

                    # æ­£è¦åŒ–åº§æ¨™ã‚’ä½¿ç”¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                    if bbox.get("normalized_vertices"):
                        vertices = self._convert_normalized_vertices(
                            bbox["normalized_vertices"], image_size
                        )
                    elif bbox.get("vertices"):
                        vertices = [(v["x"], v["y"]) for v in bbox["vertices"]]
                    else:
                        continue

                    # ãƒãƒªã‚´ãƒ³ã‚’æç”»
                    self._draw_polygon_highlight(draw, vertices, color, element.get("text", ""))

    def _draw_openai_highlights(self,
                              draw: ImageDraw.Draw,
                              data: List[Dict[str, Any]],
                              image_size: Tuple[int, int]):
        """
        OpenAI ã®çµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºï¼ˆåº§æ¨™æƒ…å ±ãŒãªã„ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã¿ï¼‰

        Args:
            draw: ImageDraw ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            data: OpenAI ã®çµæœãƒ‡ãƒ¼ã‚¿
            image_size: ç”»åƒã‚µã‚¤ã‚º
        """
        # OpenAI ã®çµæœã«ã¯åº§æ¨™æƒ…å ±ãŒãªã„ãŸã‚ã€
        # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®ã¿ã‚’ç”»åƒã®ä¸‹éƒ¨ã«è¡¨ç¤º
        if isinstance(data, list) and data:
            y_offset = image_size[1] - 200

            for i, item in enumerate(data):
                if isinstance(item, dict):
                    text_info = []
                    for key, value in item.items():
                        if value and str(value).strip():
                            text_info.append(f"{key}: {value}")

                    if text_info:
                        text = " | ".join(text_info)
                        color = self.colors[i % len(self.colors)]

                        # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
                        self._draw_text_box(draw, (10, y_offset + i * 30), text, color)

    def _convert_normalized_vertices(self,
                                   normalized_vertices: List[Dict[str, float]],
                                   image_size: Tuple[int, int]) -> List[Tuple[int, int]]:
        """
        æ­£è¦åŒ–åº§æ¨™ã‚’å®Ÿéš›ã®ç”»åƒåº§æ¨™ã«å¤‰æ›

        Args:
            normalized_vertices: æ­£è¦åŒ–åº§æ¨™ã®ãƒªã‚¹ãƒˆ
            image_size: ç”»åƒã‚µã‚¤ã‚º (width, height)

        Returns:
            å®Ÿéš›ã®åº§æ¨™ã®ãƒªã‚¹ãƒˆ
        """
        width, height = image_size
        vertices = []

        for vertex in normalized_vertices:
            x = int(vertex.get("x", 0) * width)
            y = int(vertex.get("y", 0) * height)
            vertices.append((x, y))

        return vertices

    def _draw_polygon_highlight(self,
                              draw: ImageDraw.Draw,
                              vertices: List[Tuple[int, int]],
                              color: str,
                              text: str = ""):
        """
        ãƒãƒªã‚´ãƒ³ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’æç”»

        Args:
            draw: ImageDraw ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            vertices: é ‚ç‚¹åº§æ¨™ã®ãƒªã‚¹ãƒˆ
            color: ãƒã‚¤ãƒ©ã‚¤ãƒˆè‰²
            text: è¡¨ç¤ºã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if len(vertices) < 3:
            return

        # åŠé€æ˜ã®å¡—ã‚Šã¤ã¶ã—
        fill_color = self._hex_to_rgba(color, alpha=50)
        draw.polygon(vertices, fill=fill_color)

        # å¢ƒç•Œç·š
        outline_color = self._hex_to_rgba(color, alpha=200)
        draw.polygon(vertices, outline=outline_color, width=2)

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ©ãƒ™ãƒ«ã¯è±†è…ãƒ•ã‚©ãƒ³ãƒˆå•é¡Œã‚’é¿ã‘ã‚‹ãŸã‚ã«å‰Šé™¤
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒæ­£ã—ãèª­ã¿è¾¼ã‚ãªã„ç¯å¢ƒã§ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«

    def _draw_text_box(self,
                      draw: ImageDraw.Draw,
                      position: Tuple[int, int],
                      text: str,
                      color: str):
        """
        ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’æç”»

        Args:
            draw: ImageDraw ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            position: æç”»ä½ç½®
            text: è¡¨ç¤ºã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            color: èƒŒæ™¯è‰²
        """
        x, y = position

        try:
            font = ImageFont.load_default()

            # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’å–å¾—
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]

            # èƒŒæ™¯ã‚’æç”»
            bg_color = self._hex_to_rgba(color, alpha=150)
            draw.rectangle([x, y, x + text_width + 10, y + text_height + 6],
                         fill=bg_color)

            # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
            draw.text((x + 5, y + 3), text, fill=(0, 0, 0, 255), font=font)

        except Exception:
            # ãƒ•ã‚©ãƒ³ãƒˆé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæç”»
            draw.rectangle([x, y, x + 200, y + 20],
                         fill=self._hex_to_rgba(color, alpha=150))
            draw.text((x + 5, y + 3), text[:30], fill=(0, 0, 0, 255))

    def _hex_to_rgba(self, hex_color: str, alpha: int = 255) -> Tuple[int, int, int, int]:
        """
        16é€²æ•°ã‚«ãƒ©ãƒ¼ã‚’RGBAã«å¤‰æ›

        Args:
            hex_color: 16é€²æ•°ã‚«ãƒ©ãƒ¼æ–‡å­—åˆ— (ä¾‹: "#FF6B6B")
            alpha: é€æ˜åº¦ (0-255)

        Returns:
            RGBA ã‚¿ãƒ—ãƒ«
        """
        hex_color = hex_color.lstrip('#')

        if len(hex_color) == 6:
            r = int(hex_color[0:2], 16)
            g = int(hex_color[2:4], 16)
            b = int(hex_color[4:6], 16)
            return (r, g, b, alpha)
        else:
            return (255, 0, 0, alpha)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯èµ¤

    def display_ocr_results_with_highlights(self,
                                          image_file,
                                          ocr_result: Dict[str, Any]):
        """
        OCRçµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãã§è¡¨ç¤º

        Args:
            image_file: å…ƒã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
            ocr_result: OCRå‡¦ç†çµæœ
        """
        st.subheader("ğŸ“ OCRçµæœã®ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š
        if ocr_result.get("source") == "document_ai":
            highlight_level = "paragraphs"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§paragraphsã‚’ä½¿ç”¨
        else:
            highlight_level = "openai"
            st.info("OpenAI ã®çµæœã«ã¯åº§æ¨™æƒ…å ±ãŒãªã„ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

        # ãƒã‚¤ãƒ©ã‚¤ãƒˆç”»åƒã‚’ä½œæˆ
        highlighted_image = self.create_highlighted_image(
            image_file, ocr_result, highlight_level
        )

        # if highlighted_image:
        #     # ç”»åƒã‚’è¡¨ç¤º
        #     # st.image(highlighted_image,
        #     #         caption=f"ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º ({highlight_level})",
        #     #         use_column_width=True)

        #     # # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
        #     # self._display_detailed_results(ocr_result, highlight_level)
        # else:
        #     st.error("ãƒã‚¤ãƒ©ã‚¤ãƒˆç”»åƒã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    def _display_detailed_results(self,
                                ocr_result: Dict[str, Any],
                                highlight_level: str):
        """
        è©³ç´°ãªOCRçµæœã‚’è¡¨ç¤º

        Args:
            ocr_result: OCRå‡¦ç†çµæœ
            highlight_level: ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«
        """
        if not ocr_result.get("success"):
            st.error(f"OCRå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {ocr_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            return

        data = ocr_result.get("data", {})
        source = ocr_result.get("source", "unknown")

        if source == "document_ai":
            self._display_document_ai_details(data, highlight_level)
        elif source == "openai":
            self._display_openai_details(data)

    def _display_document_ai_details(self,
                                   data: Dict[str, Any],
                                   highlight_level: str):
        """
        Document AI ã®è©³ç´°çµæœã‚’è¡¨ç¤º

        Args:
            data: Document AI ã®çµæœãƒ‡ãƒ¼ã‚¿
            highlight_level: ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ«
        """
        # ãƒšãƒ¼ã‚¸æƒ…å ±
        if data.get("pages"):
            page = data["pages"][0]

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("ãƒšãƒ¼ã‚¸ç•ªå·", page.get("page_number", 1))

            with col2:
                dimensions = page.get("dimensions", {})
                st.metric("å¹…", f"{dimensions.get('width', 0):.0f}px")

            with col3:
                st.metric("é«˜ã•", f"{dimensions.get('height', 0):.0f}px")

            # â†“â†“â†“ Paragraphsè©³ç´°ã‚„è¦ç´ ãƒªã‚¹ãƒˆã®è¡¨ç¤ºã¯å‰Šé™¤ï¼ˆä½•ã‚‚è¡¨ç¤ºã—ãªã„ï¼‰
            # ã“ã“ã«ã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

    def _display_openai_details(self, data: List[Dict[str, Any]]):
        """
        OpenAI ã®è©³ç´°çµæœã‚’è¡¨ç¤º

        Args:
            data: OpenAI ã®çµæœãƒ‡ãƒ¼ã‚¿
        """
        if isinstance(data, list):
            st.subheader(f"ğŸ“ æŠ½å‡ºã•ã‚ŒãŸé …ç›® ({len(data)}å€‹)")

            for i, item in enumerate(data):
                st.markdown(f"### é …ç›® {i+1}")
                if isinstance(item, dict):
                    for j, (key, value) in enumerate(item.items()):
                        if value and str(value).strip():
                            # ã‚ˆã‚Šä¸€æ„æ€§ã®é«˜ã„ã‚­ãƒ¼ã‚’ç”Ÿæˆ
                            unique_key = f"openai_detail_{i}_{j}_{key}_{int(time.time() * 1000000) % 1000000}"
                            # ASCII codec ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã€æ–‡å­—åˆ—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‡¦ç†
                            try:
                                display_value = str(value)
                            except UnicodeEncodeError:
                                display_value = str(value).encode('utf-8', errors='ignore').decode('utf-8')
                            st.text_area(key, display_value, height=100, key=unique_key)
                else:
                    st.text(str(item))

                if i < len(data) - 1:  # æœ€å¾Œã®é …ç›®ä»¥å¤–ã¯åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ 
                    st.divider()
        else:
            st.json(data)

    def create_comparison_view(self,
                             image_file,
                             ocr_results: List[Dict[str, Any]]):
        """
        è¤‡æ•°ã®OCRçµæœã®æ¯”è¼ƒè¡¨ç¤º

        Args:
            image_file: å…ƒã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
            ocr_results: OCRçµæœã®ãƒªã‚¹ãƒˆ
        """
        st.subheader("ğŸ” OCRçµæœæ¯”è¼ƒ")

        if len(ocr_results) < 2:
            st.warning("æ¯”è¼ƒã™ã‚‹ã«ã¯2ã¤ä»¥ä¸Šã®OCRçµæœãŒå¿…è¦ã§ã™ã€‚")
            return

        # çµæœã‚’ä¸¦ã¹ã¦è¡¨ç¤º
        cols = st.columns(len(ocr_results))

        for i, (col, result) in enumerate(zip(cols, ocr_results)):
            with col:
                source = result.get("source", f"çµæœ{i+1}")
                st.subheader(f"{source.upper()}")

                if result.get("success"):
                    # ãƒã‚¤ãƒ©ã‚¤ãƒˆç”»åƒã‚’ä½œæˆ
                    highlight_level = "paragraphs" if source == "document_ai" else "openai"
                    highlighted_image = self.create_highlighted_image(
                        image_file, result, highlight_level
                    )

                    if highlighted_image:
                        st.image(highlighted_image, use_column_width=True)

                    # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºçµæœ
                    data = result.get("data", {})
                    if isinstance(data, dict) and data.get("text"):
                        st.text_area("æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ", data["text"], height=150)
                    elif isinstance(data, list):
                        text_parts = []
                        for item in data:
                            if isinstance(item, dict):
                                for value in item.values():
                                    if value and str(value).strip():
                                        text_parts.append(str(value))
                        st.text_area("æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ", "\n".join(text_parts), height=150)
                else:
                    st.error(f"å‡¦ç†å¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
